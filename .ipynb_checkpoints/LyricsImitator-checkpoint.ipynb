{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1fe3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc05042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1153\n"
     ]
    }
   ],
   "source": [
    "artist = \"Slenderbodies\"\n",
    "dataPath = f\"./Dataset/{artist}/\"\n",
    "lyrics = \"\"\n",
    "\n",
    "for song in listdir(dataPath):\n",
    "    with open(dataPath + song, mode = \"r\") as songFile:\n",
    "        lyrics += songFile.read().lower()\n",
    "        \n",
    "lyrics = lyrics.split(\"\\n\")\n",
    "print(f\"Number of sentences: {len(lyrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aee08f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39159f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num words: 967\n",
      "=====\n",
      "Word Index Dictionary\n",
      "{'i': 1, 'you': 2, 'the': 3, 'to': 4, 'my': 5, 'a': 6, 'be': 7, 'in': 8, 'all': 9, 'your': 10, \"it's\": 11, 'me': 12, 'it': 13, 'and': 14, 'been': 15, 'of': 16, 'away': 17, 'from': 18, 'up': 19, 'one': 20, 'stay': 21, \"don't\": 22, 'so': 23, 'like': 24, 'want': 25, 'on': 26, 'for': 27, 'way': 28, 'tangled': 29, 'us': 30, \"i've\": 31, 'that': 32, \"can't\": 33, 'just': 34, 'feeling': 35, 'yeah': 36, 'between': 37, 'this': 38, 'could': 39, 'back': 40, 'little': 41, 'have': 42, 'we': 43, 'belong': 44, 'down': 45, 'long': 46, 'if': 47, 'but': 48, 'senses': 49, 'time': 50, \"i'm\": 51, 'take': 52, 'got': 53, 'too': 54, 'wallow': 55, 'how': 56, \"you're\": 57, 'love': 58, 'know': 59, 'let': 60, 'better': 61, 'nothing': 62, 'maybe': 63, 'something': 64, 'still': 65, 'with': 66, 'folds': 67, 'here': 68, 'no': 69, 'seems': 70, 'feel': 71, 'pressure': 72, 'now': 73, 'our': 74, 'home': 75, 'out': 76, 'ah': 77, 'night': 78, 'end': 79, 'get': 80, 'right': 81, 'at': 82, 'is': 83, 'were': 84, 'funny': 85, 'wanna': 86, 'yet': 87, 'where': 88, 'make': 89, 'see': 90, 'over': 91, 'about': 92, 'less': 93, 'human': 94, 'as': 95, 'dangerous': 96, 'fine': 97, 'go': 98, \"won't\": 99, 'do': 100, 'when': 101, 'even': 102, 'eyes': 103, 'while': 104, 'left': 105, 'can': 106, 'its': 107, 'tell': 108, 'place': 109, 'said': 110, 'breath': 111, 'ooh': 112, 'mm': 113, 'nate': 114, 'remember': 115, 'gone': 116, 'spend': 117, 'try': 118, 'tried': 119, 'bow': 120, \"we're\": 121, \"'em\": 122, 'need': 123, 'never': 124, 'wrong': 125, 'myself': 126, 'sun': 127, \"we'll\": 128, 'head': 129, 'together': 130, 'day': 131, 'come': 132, 'life': 133, \"i'll\": 134, 'always': 135, 'what': 136, 'along': 137, 'say': 138, 'blue': 139, 'ive': 140, 'through': 141, \"'til\": 142, 'she': 143, 'every': 144, 'alone': 145, 'tonight': 146, 'alright': 147, 'are': 148, 'world': 149, 'slow': 150, 'hold': 151, 'into': 152, 'lately': 153, 'her': 154, 'bit': 155, \"there's\": 156, 'will': 157, 'trying': 158, 'mess': 159, 'best': 160, 'light': 161, 'until': 162, 'only': 163, 'step': 164, 'think': 165, 'may': 166, 'oh': 167, 'gray': 168, 'mine': 169, 'run': 170, 'mind': 171, 'else': 172, \"moods'\": 173, 'dependent': 174, 'lost': 175, 'was': 176, 'anything': 177, 'inside': 178, 'heart': 179, 'la': 180, 'morning': 181, 'intentional': 182, \"you'll\": 183, 'these': 184, 'days': 185, \"didn't\": 186, 'hard': 187, 'found': 188, 'some': 189, 'leaves': 190, 'spent': 191, 'honest': 192, 'conceal': 193, 'show': 194, 'would': 195, 'miscalculated': 196, 'baby': 197, 'whole': 198, 'off': 199, 'don’t': 200, 'deep': 201, 'hear': 202, 'by': 203, 'own': 204, 'mmm': 205, 'falling': 206, 'skin': 207, 'look': 208, 'lover': 209, 'wake': 210, 'hiding': 211, 'making': 212, 'any': 213, 'going': 214, 'corner': 215, 'feet': 216, 'made': 217, 'heard': 218, 'loose': 219, 'paranoid': 220, 'touch': 221, 'noise': 222, 'body': 223, 'luck': 224, \"mood's\": 225, 'saying': 226, 'backwards': 227, 'since': 228, 'than': 229, 'below': 230, 'much': 231, 'breathing': 232, 'give': 233, 'wait': 234, 'then': 235, 'stranded': 236, 'cold': 237, \"'cause\": 238, 'face': 239, 'does': 240, 'dark': 241, 'da': 242, 'friend': 243, 'lose': 244, 'fall': 245, 'call': 246, 'there': 247, 'na': 248, \"you'd\": 249, 'empty': 250, 'follow': 251, 'side': 252, 'treat': 253, 'im': 254, 'far': 255, 'baroness': 256, 'bet': 257, \"she's\": 258, 'common': 259, 'above': 260, 'aah': 261, 'against': 262, 'bridges': 263, 'distant': 264, 'sirens': 265, 'fade': 266, 'islands': 267, 'nobody': 268, 'i’ve': 269, 'again': 270, 'dependin’': 271, 'am': 272, 'name': 273, 'because': 274, 'sea': 275, 'spill': 276, 'sanity': 277, 'wilted': 278, 'winds': 279, 'wealth': 280, 'born': 281, 'behave': 282, 'ruminate': 283, 'steps': 284, 'woke': 285, 'asked': 286, 'everyday': 287, 'used': 288, 'melt': 289, 'sentimental': 290, 'thoughts': 291, 'underwater': 292, 'ocean': 293, 'floor': 294, 'it’s': 295, 'lets': 296, 'around': 297, 'dance': 298, 'move': 299, 'stone': 300, 'did': 301, 'sitting': 302, 'fire': 303, 'lonely': 304, 'told': 305, 'loud': 306, 'ceiling': 307, 'palaces': 308, 'countrysides': 309, 'laughing': 310, 'break': 311, 'city': 312, 'lights': 313, 'couple': 314, 'pretend': 315, 'leave': 316, 'swimming': 317, 'losing': 318, 'find': 319, 'once': 320, 'blood': 321, 'sure': 322, 'wanted': 323, 'soon': 324, 'close': 325, 'slip': 326, 'id': 327, 'beauty': 328, 'sweet': 329, 'hoping': 330, 'grow': 331, 'old': 332, 'keeping': 333, 'guess': 334, 'sense': 335, 'pictures': 336, 'riding': 337, 'asleep': 338, 'suddenly': 339, 'breeze': 340, 'soul': 341, 'play': 342, 'keep': 343, 'lay': 344, \"dependin'\": 345, 'air': 346, 'shame': 347, 'sway': 348, 'ears': 349, 'yours': 350, 'sinning': 351, 'black': 352, 'i’ll': 353, 'glow': 354, 'polychrome': 355, 'seem': 356, 'craving': 357, 'we’ve': 358, 'miming': 359, 'animals': 360, 'following': 361, 'same': 362, 'scars': 363, 'perfect': 364, 'picture': 365, 'everything': 366, 'forgetting': 367, 'clearer': 368, 'alive': 369, 'bones': 370, 'sent': 371, 'drowning': 372, 'anemone': 373, 'pulls': 374, 'destiny': 375, 'fatal': 376, 'recipe': 377, 'road': 378, 'speak': 379, 'living': 380, 'flakes': 381, 'peeling': 382, 'reasons': 383, 'done': 384, 'amends': 385, 'not': 386, 'bad': 387, 'wading': 388, 'subliminal': 389, 'rolling': 390, 'warm': 391, 'memories': 392, \"we'd\": 393, 'doubt': 394, 'lived': 395, 'breathe': 396, 'dream': 397, 'believe': 398, 'another': 399, 'heavy': 400, 'able': 401, 'awkward': 402, 'you’re': 403, 'bent': 404, 'outward': 405, 'talk': 406, 'we’ll': 407, 'gold': 408, 'well': 409, 'evermore': 410, 'yourself': 411, 'anymore': 412, 'you’ve': 413, 'turn': 414, 'door': 415, \"you've\": 416, 'reflection': 417, 'such': 418, 'fault': 419, 'dewdrop': 420, 'trickles': 421, 'crystal': 422, 'glowing': 423, 'letting': 424, 'subtle': 425, 'ways': 426, 'create': 427, 'grave': 428, 'theres': 429, 'bout': 430, 'ur': 431, 'pain': 432, 'gonna': 433, 'had': 434, 'whispers': 435, 'ear': 436, 'quite': 437, 'lovely': 438, 'feels': 439, 'shadows': 440, 'strong': 441, 'farther': 442, 'reach': 443, 'among': 444, 'sound': 445, 'makes': 446, 'places': 447, 'distance': 448, 'listens': 449, 'martyr': 450, 'learn': 451, 'floating': 452, 'or': 453, 'fooling': 454, 'an': 455, 'start': 456, 'ready': 457, 'overtake': 458, 'fate': 459, 'mood’s': 460, 'spine': 461, 'saw': 462, 'drip': 463, 'vision': 464, 'flawless': 465, 'await': 466, 'full': 467, 'reveal': 468, 'captivated': 469, 'reel': 470, 'symphonies': 471, 'voice': 472, 'hidden': 473, 'theirs': 474, 'cacophony': 475, 'ringing': 476, 'white': 477, 'more': 478, 'cool': 479, 'act': 480, 'fool': 481, 'offer': 482, 'silly': 483, 'things': 484, 'basis': 485, 'late': 486, 'carry': 487, 'carried': 488, 'seeing': 489, 'blooming': 490, 'muted': 491, 'opal': 492, 'pink': 493, 'hue': 494, 'surrounds': 495, 'lie': 496, 'stop': 497, 'beg': 498, 'madman': 499, 'took': 500, 'might': 501, 'under': 502, 'calling': 503, 'waiting': 504, 'king': 505, 'drawing': 506, 'somebody': 507, 'holding': 508, 'borrow': 509, 'tomorrow': 510, 'fell': 511, 'track': 512, 'chin': 513, 'sags': 514, 'hey': 515, 'words': 516, 'times': 517, 'hand': 518, 'tight': 519, 'crazy': 520, 'minds': 521, 'dust': 522, 'heights': 523, 'daylight': 524, \"something's\": 525, 'held': 526, 'cleaned': 527, 'fun': 528, 'leaning': 529, 'rules': 530, 'laborious': 531, 'lobotomy': 532, 'performed': 533, 'questions': 534, 'morphine': 535, 'toxic': 536, 'chemicals': 537, 'intoxicated': 538, 'dizzy': 539, 'hypnotized': 540, 'scent': 541, 'mental': 542, 'everydaydown': 543, 'wander': 544, 'you’ll': 545, 'sandy': 546, 'quiet': 547, 'pause': 548, \"he's\": 549, 'send': 550, 'dreaming': 551, '‘bout': 552, 'lifebend': 553, 'silhouette': 554, 'holds': 555, 'youthful': 556, 'highly': 557, 'though': 558, 'seek': 559, 'tryna': 560, 'chase': 561, 'caught': 562, 'bedside': 563, 'resuscitated': 564, 'tone': 565, 'reminds': 566, 'ones': 567, 'met': 568, 'tribe': 569, 'strangers': 570, 'fingers': 571, 'receive': 572, 'helps': 573, 'depending': 574, 'people': 575, 'share': 576, \"chemicalsit's\": 577, \"sun's\": 578, 'setting': 579, \"they're\": 580, 'felt': 581, 'yougod': 582, 'damn': 583, 'mean': 584, 'swear': 585, 'greeted': 586, 'sometimes': 587, 'blessed': 588, 'they': 589, 'reason': 590, 'season': 591, 'minutes': 592, 'forth': 593, 'leaving': 594, \"belongi'm\": 595, 'mended': 596, 'prime': 597, 'eyelids': 598, 'steady': 599, 'mindset': 600, 'shifts': 601, 'probable': 602, 'let’s': 603, 'hate': 604, 'goodbyes': 605, 'true': 606, 'slide': 607, \"pupil's\": 608, 'perspective': 609, 'neglected': 610, \"let's\": 611, 'oohdrip': 612, 'mouth': 613, 'ground': 614, 'lying': 615, 'awake': 616, 'golden': 617, 'gather': 618, 'hounds': 619, 'dog': 620, 'pound': 621, 'cat': 622, 'blanket': 623, 'reborn': 624, 'puff': 625, 'deserved': 626, 'pray': 627, 'someday': 628, 'pair': 629, 'shoes': 630, 'walked': 631, 'mile': 632, 'blistered': 633, 'forest': 634, 'rains': 635, 'demon': 636, 'hell': 637, 'summer': 638, 'you’d': 639, 'cry': 640, 'smile': 641, 'stuck': 642, 'rut': 643, 'goldheard': 644, 'before': 645, 'reaching': 646, '84': 647, '18': 648, 'finest': 649, 'each': 650, 'expression': 651, 'spite': 652, 'sad': 653, 'foundfind': 654, 'delight': 655, 'sweeter': 656, 'water': 657, 'sending': 658, 'pleasance': 659, 'lock': 660, 'muse': 661, 'timeless': 662, 'oceans': 663, 'moon': 664, 'sprawled': 665, 'sunday': 666, 'receiving': 667, 'spoon': 668, 'crackle': 669, 'scented': 670, 'desires': 671, 'melting': 672, 'petals': 673, 'cling': 674, 'different': 675, 'shades': 676, 'hues': 677, 'lush': 678, 'reminders': 679, 'imbue': 680, 'all…lately': 681, 'thinking': 682, 'harmony': 683, \"thinkin'\": 684, \"'bout\": 685, 'beenslip': 686, 'thing': 687, 'looked': 688, 'bright': 689, \"'fore\": 690, 'hollow': 691, 'dug': 692, 'oooh': 693, 'poised': 694, 'youve': 695, 'flown': 696, 'forgot': 697, 'past': 698, 'youre': 699, 'crack': 700, 'locked': 701, 'getaway': 702, 'years': 703, 'mark': 704, 'scheming': 705, 'visions': 706, 'space': 707, 'splash': 708, 'paint': 709, 'watch': 710, 'ends': 711, 'curl': 712, 'dry': 713, 'rays': 714, 'escape': 715, 'hideaway': 716, 'hearyeah': 717, 'figured': 718, 'fighting': 719, 'throne': 720, 'troubled': 721, 'crowd': 722, 'polaroid': 723, 'fading': 724, 'quickly': 725, 'invites': 726, 'senseoh': 727, 'monotone': 728, 'taste': 729, 'decisions': 730, 'nonsensical': 731, 'finding': 732, 'mistakes': 733, 'irunning': 734, 'seas': 735, 'trouble': 736, 'weariness': 737, 'half': 738, 'ok': 739, 'haze': 740, 'dripping': 741, 'safe': 742, 'matter': 743, 'hysteria': 744, 'irony': 745, 'future': 746, 'dont': 747, 'devolve': 748, 'crows': 749, 'keys': 750, 'rabbits': 751, 'peering': 752, 'forever': 753, 'young': 754, 'loon': 755, 'dosage': 756, 'arms': 757, \"ain't\": 758, 'inch': 759, 'closer': 760, 'homei': 761, 'reality': 762, \"might've\": 763, 'missed': 764, 'echo': 765, 'keeps': 766, 'easy': 767, 'dangerousmy': 768, 'float': 769, 'written': 770, 'sleeve': 771, 'boy': 772, \"winter's\": 773, 'teeth': 774, 'feed': 775, 'later': 776, 'faded': 777, \"what's\": 778, 'goin': 779, 'sunsomething': 780, 'boiling': 781, 'candlelight': 782, 'scents': 783, 'clothes': 784, 'strewn': 785, 'potent': 786, 'smiles': 787, 'liquid': 788, 'twirling': 789, 'vine': 790, 'dipping': 791, 'toes': 792, 'moonlight': 793, 'hid': 794, 'cocoons': 795, 'slunk': 796, 'pools': 797, 'swore': 798, \"i'd\": 799, 'nothingso': 800, 'hung': 801, 'dip': 802, 'search': 803, 'hide': 804, 'underneath': 805, 'gasp': 806, 'grasp': 807, 'deceive': 808, 'sing': 809, 'songs': 810, 'enchant': 811, 'stories': 812, 'noiseyou': 813, 'wildfire': 814, 'wild': 815, 'kids': 816, 'ours': 817, 'dead': 818, 'running': 819, 'chasing': 820, 'after': 821, 'trust': 822, 'became': 823, 'who': 824, 'tore': 825, 'apart': 826, 'usi': 827, 'underneathlens': 828, 'flare': 829, 'aching': 830, 'covers': 831, 'cannibal': 832, 'glossed': 833, 'lines': 834, 'crisp': 835, 'cream': 836, 'silky': 837, 'motion': 838, 'north': 839, 'shore': 840, 'floats': 841, 'slowly': 842, 'flows': 843, 'motionyou': 844, 'tails': 845, 'roam': 846, 'briefly': 847, 'i’m': 848, 'coming': 849, 'clean': 850, 'pupils': 851, 'bauble': 852, 'blues': 853, 'lamenting': 854, 'september’s': 855, 'sunsets': 856, 'cascade': 857, 'why': 858, 'twice': 859, 'afterglowlooking': 860, 'sky': 861, 'fingertips': 862, 'walking': 863, 'colors': 864, 'surreal': 865, 'crystals': 866, 'tesselate': 867, 'single': 868, 'drew': 869, 'itfeeling': 870, 'obvious': 871, 'minute': 872, 'matching': 873, 'swaying': 874, 'has': 875, 'weak': 876, 'drink': 877, 'two': 878, 'lighten': 879, 'sleep': 880, 'nightly': 881, 'weekend': 882, 'type': 883, 'images': 884, 'forget': 885, 'wonder': 886, 'rise': 887, 'youwarm': 888, 'form': 889, 'thrown': 890, 'fake': 891, 'callow': 892, 'help': 893, 'waynah': 894, 'naive': 895, 'onto': 896, 'ease': 897, 'often': 898, 'height': 899, 'mountains': 900, 'kept': 901, 'sleeping': 902, 'chuckling': 903, 'softly': 904, 'pass': 905, 'graciously': 906, 'myive': 907, 'thousand': 908, 'sticks': 909, 'moment': 910, 'clear': 911, 'sublime': 912, 'free': 913, 'unwind': 914, 'many': 915, 'today': 916, 'yea': 917, 'known': 918, 'slipped': 919, 'heres': 920, 'finally': 921, 'spare': 922, 'second': 923, 'appreciate': 924, 'impressed': 925, 'sublimefeels': 926, 'nice': 927, 'driving': 928, 'coastline': 929, 'gripping': 930, 'honey': 931, 'enough': 932, 'seen': 933, 'sights': 934, 'teenage': 935, 'vibes': 936, 'reminiscing': 937, 'feeble': 938, 'lives': 939, 'pretty': 940, 'homenuisance': 941, 'eyed': 942, 'paradise': 943, \"cupid's\": 944, 'blind': 945, 'watching': 946, 'mesmerized': 947, 'paralyzed': 948, 'oily': 949, 'goosebumps': 950, 'shiver': 951, 'without': 952, 'blushing': 953, 'red': 954, 'tingle': 955, 'moving': 956, 'satisfied': 957, 'upfeeling': 958, 'breaking': 959, \"in's\": 960, 'charm': 961, \"me's\": 962, 'harm': 963, 'fess': 964, 'them': 965, 'large': 966}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lyrics)               # Generate the word index dictionary\n",
    "totalWords = len(tokenizer.word_index) + 1   # With padding which is 0\n",
    "\n",
    "print(f\"Total num words: {totalWords}\")\n",
    "print(\"=====\")\n",
    "print(\"Word Index Dictionary\")\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d87792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "\n",
    "for line in lyrics:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        \n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = \"pre\"))\n",
    "xs, labels = input_sequences[:,:-1] , input_sequences[:,-1]\n",
    "ys = to_categorical(labels, num_classes = totalWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a291fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: ['and', 'leaning', 'backwards']\n",
      "Token list: [14, 529, 227]\n",
      "\n",
      "Padded token list: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14]\n",
      "Decoded token list to text: ['and']\n",
      "\n",
      "One-hot label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "Index of label: 529\n",
      "Decoded Label: picture\n"
     ]
    }
   ],
   "source": [
    "sentence = lyrics[0].split(\" \")\n",
    "print(f\"Sample sentence: {sentence}\")\n",
    "\n",
    "token_list = []\n",
    "for word in sentence: \n",
    "    token_list.append(tokenizer.word_index[word])\n",
    "\n",
    "print(f\"Token list: {token_list}\")\n",
    "\n",
    "print(f\"\\nPadded token list: {xs[0]}\")\n",
    "print(f\"Decoded token list to text: {tokenizer.sequences_to_texts([xs[0]])}\")\n",
    "\n",
    "print(f\"\\nOne-hot label: {ys[0]}\")\n",
    "print(f\"Index of label: {np.argmax(ys[0])}\")\n",
    "print(f\"Decoded Label: {tokenizer.index_word[np.argmax(ys[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9a5553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 16, 100)           96700     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300)              301200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 967)               291067    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 688,967\n",
      "Trainable params: 688,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddingDim = 100\n",
    "lstmUnits = 150\n",
    "learningRate = 0.01\n",
    "\n",
    "model = Sequential([\n",
    "          Embedding(totalWords, embeddingDim, input_length = max_sequence_len - 1),\n",
    "          Bidirectional(LSTM(lstmUnits)),\n",
    "          Dense(totalWords, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = Adam(learning_rate = learningRate), \n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749da770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "171/171 [==============================] - 11s 38ms/step - loss: 5.2256 - accuracy: 0.1369\n",
      "Epoch 2/40\n",
      "171/171 [==============================] - 5s 31ms/step - loss: 3.3139 - accuracy: 0.3819\n",
      "Epoch 3/40\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 2.1384 - accuracy: 0.5443\n",
      "Epoch 4/40\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 1.4073 - accuracy: 0.6667\n",
      "Epoch 5/40\n",
      "171/171 [==============================] - 6s 35ms/step - loss: 1.0157 - accuracy: 0.7567\n",
      "Epoch 6/40\n",
      "171/171 [==============================] - 6s 34ms/step - loss: 0.7835 - accuracy: 0.8113\n",
      "Epoch 7/40\n",
      " 37/171 [=====>........................] - ETA: 4s - loss: 0.5801 - accuracy: 0.8480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10280\\59213564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[1;32m--> 135\u001b[1;33m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 53\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(xs, ys, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c962a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"The sky's cloudy but it never rains\"\n",
    "next_words = 50\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen = max_sequence_len - 1, padding = \"pre\")\n",
    "\n",
    "    probabilities = model.predict(token_list)\n",
    "    predicted = np.argmax(probabilities, axis = -1)[0]\n",
    "    if(predicted != 0):\n",
    "        output_word = tokenizer.index_word[predicted]\n",
    "        seed_text += \" \" + output_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=============================================== Generated Lyrics ===============================================\\n\")\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1293504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
